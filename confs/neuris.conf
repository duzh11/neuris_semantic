general {
    dataset_type = indoor #dtu/indoor
    scan_name = scene0435_02
    exp_name = test/test #exp_scene0625_00

    exp_dir =  ../exps    # exp dir format: base_exp_dir/dataset_type/scan_name/exp_name
    data_dir = ../Data/dataset
    model_type = neus  #neus/nerf/semantic
    recording = [
        ./,
        ./models
    ]
}

dataset {
    denoise_gray_image = True  # denoise gray image
    denoise_paras = [7, 21, 10, 10]
    
    # patch-match
    patchmatch_start = 6e4
    patchmatch_mode = use_geocheck # 是否自适应添加normal
    patchmatch_thres_ncc_robust = 0.66 
    check_occlusion = True

    mode_init_accum = model  # model/npz
    init_accum_reso_level = 4
    init_accum_step_npz = 6e4 
    
    sample_range_indoor = 2.0
    
    bbox_size_half = 1.0
    sphere_radius = 1.0
    resolution_level = 1.0

    estimate_scale_mat = False
    cache_all_data = False
    mask_out_image = False

    semantic_type=deeplab
    semantic_class=40 #3,40,13
    MANHATTAN = False
    
    use_semantic_uncer = False
    semantic_uncer_type = viewAL/viewAL
    exp_score = True
    semantic_filter = False
    filter_confidence = 0.5

    #slic: slic_40_10_0, slic_60_10_0, slic_80_10_0
    #felzenszwalb: felzenszwalb_100_1_50, felzenszwalb_100_1_50_a
    #SAM：SAM, RGB_SAM，RGB_SAM_paraSSA，normal_SAM，normal_SAM_paraSSA
    grids_type = SAM
}

train {
    batch_size = 512 #128

    learning_rate = 2e-4
    learning_rate_milestone = [ 100000, 150000, 200000 ]
    learning_rate_factor = 0.5
    end_iter = 50 # 50

    save_freq = 5000#20000
    val_image_freq = 40 #图片
    save_normamap_npz = False #for patch-match validation
    val_mesh_freq  = 40 #抽取点云
    val_depth_freq = 1000000
    val_fields_freq = 1000000
    freq_valid_points = 50000
    freq_valid_weights = 500000
    freq_save_confidence = 2000000
    report_freq = 10

    validate_resolution_level = 2
    anneal_start = 0
    anneal_end = 25000
    use_white_bkgd = False

    warm_up_end = 5000
    learning_rate_alpha = 0.05
}

model {
    tiny_nerf {
        D = 8,
        d_in = 4,
        d_in_view = 3,
        W = 256,
        multires = 10,
        multires_view = 4,
        output_ch = 4,
        skips=[4],
        use_viewdirs=True
    }

    nerf {
        D = 8,
        d_in = 3,
        d_in_view = 3,
        W = 256,
        multires = 10,
        multires_view = 4,
        output_ch = 4,
        skips=[4],
        use_viewdirs=True
    }

    sdf_network {
        bias = 0.6

        #network
        d_out = 257
        d_in = 3
        d_hidden = 256
        n_layers = 8
        skip_in = [4]
        scale = 1.0
        geometric_init = True
        reverse_geoinit = True   # for indoor data
        weight_norm = True
        activation = softplus

        # embedding
        multires = 6
        use_emb_c2f = False
        emb_c2f_start = 0.1
        emb_c2f_end = 0.5
    }

    variance_network {
        init_val = 0.3
        use_fixed_variance = False
    }

    semantic_network{
        d_in=259
        d_hidden=256
        n_layers=4
        skips=[]
        multires=-1
        activation=relu
        weight_norm=True
    }

    rendering_network {
        d_feature = 256
        mode = idr  # no_view_dir / idr / no_normal
        d_in = 9    # 6 / 9
        d_out = 3
        d_hidden = 256
        n_layers = 4
        weight_norm = True
        multires_view = 4
        squeeze_out = True
    }

    neus_renderer {
        # for neus rendering
        n_samples = 64
        n_importance = 64
        n_outside = 0
        # up_sample_steps = 4
        perturb = 1.0
        alpha_type = div

        semantic_mode = none
        stop_ce_grad = True
    }

    nerf_renderer {
        # for nerf rendering
        n_samples = 64
        n_importance = 64
        n_outside = 0
        perturb = 1.0
    }

    loss {
        # Loss
        color_weight = 1.0
        igr_weight = 0.1
        mask_weight = 0.0
        smooth_weight = 0.0

        # depth and normal priors
        depth_weight = 0.0
        normal_weight = 0.0

        # plane priors
        plane_loss_milestone = 1e5
        normal_consistency_weight = 0.5   
        plane_offset_weight = 0.0
        manhattan_constrain_weight = 0.0

        # use_planes_depth
        planedepth_loss_milestone = 20
        plane_depth_mode = diff_offset
        plane_depth_weight = 0.5

        # semantic priors
        ce_mode = ce_loss
        semantic_weight = 0.5
        
        joint_loss_milestone = 20
        joint_mode=true_se
        joint_weight = 0
        
        svcon_loss_milestone = 20
        sv_con_mode = num
        sv_con_loss = ce_loss
        sv_con_weight = 0

        sem_con_loss = prob
        sem_con_weight = 0
        
        warm_up_start = 0 # normal loss
        warm_up_end = 2e4
    }
}